<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>OpenTSLM: Language models that understand time series</title>
  <link rel="stylesheet" href="/styles.css">
</head>
<body>
  <header>
    <h1>OpenTSLM: Language models that understand time series</h1>
    <p><small>Published: 2025-10-01T17:25:33+00:00</small></p>
  </header>

  <main>
    <p>Paper: <a href="https://www.opentslm.com/OpenTSLM-whitepaper.pdf" rel="nofollow">https://www.opentslm.com/OpenTSLM-whitepaper.pdf</a><p>Repo: <a href="https://github.com/StanfordBDHG/OpenTSLM" rel="nofollow">https://github.com/StanfordBDHG/OpenTSLM</a><p>Foundation models excel at text, images, audio, and video, but lack temporal reasoning capabilities over time-series data streams that run the real world: vitals, prices, telemetry, grid loads, clickstreams, machine logs, business processes.<p>Time Series Language Models (TSLMs) are open foundation models, supporting time‑series as a native modality, next to text, letting users ask questions, get explanations, and recommendations, all in natural language.<p>The OpenTSLM White Paper released today demonstrates state-of-the-art temporal reasoning performance. Unlike prior approaches, the cross-attention architecture scales to long time-series remaining viable at scale.<p>The results:<p>- Sleep staging: 4.4× accuracy with a model 200× smaller (~880× efficiency)<p>- Activity recognition: ~6× accuracy with 200× smaller (~1,000× efficiency)<p>- ECG interpretation: ~2× accuracy with 200× smaller (~400× efficiency)<p>— first model to process 12-lead ECG signals and text simultaneously with chain-of-thought reasoning validated by cardiologists.<p>For the first time, foundation models can handle multiple time-series streams of varying lengths concurrently, integrate them with textual context, and produce <i>interpretable</i> explanations (verified by domain experts, clinicians).<p>This work is the result of a growing collaboration between researchers from Stanford, ETH Zurich, UIUC, University of St. Gallen, University of Washington, Google, and Amazon.<p>It points to the next foundation model frontier: temporal intelligence that unlocks proactive healthcare, adaptive robotics, resilient infrastructure, and new forms of human-AI collaboration.</p>
<hr />
<p>Comments URL: <a href="https://news.ycombinator.com/item?id=45440431">https://news.ycombinator.com/item?id=45440431</a></p>
<p>Points: 230</p>
<p># Comments: 70</p>
    <p><a href="https://www.opentslm.com/" rel="noopener noreferrer">Source</a></p>
  </main>

  <aside>
    <!-- Paste AdSense snippet here -->

  </aside>

  <script src="/site.js"></script>
</body>
</html>
