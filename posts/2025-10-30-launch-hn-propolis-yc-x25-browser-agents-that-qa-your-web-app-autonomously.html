<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Launch HN: Propolis (YC X25) – Browser agents that QA your web app autonomously</title>
  <link rel="stylesheet" href="/styles.css">
</head>
<body>
  <header>
    <h1>Launch HN: Propolis (YC X25) – Browser agents that QA your web app autonomously</h1>
    <p><small>Published: 2025-10-30T16:40:02+00:00</small></p>
  </header>

  <main>
    <p>Hi HN, we're Marc and Matt, and we're building Propolis (app.propolis.tech/#/launch). We use browser agents to simulate users in order to report bugs and write e2e tests. Today, you can launch 10s-100s of agents that collaboratively explore a website and report back on pain points + propose e2e tests that can run as part of your CI.<p>You can try an initial run (two minute set up) to get a feel for the product for free here: app.propolis.tech/#/launch. Or watch our demo video: <a href="https://www.tella.tv/video/autonomous-qa-system-walkthrough-3s4e">https://www.tella.tv/video/autonomous-qa-system-walkthrough-...</a><p>The Problem<p>Both Matt and I have been thinking about software quality for the last 10 years. While at Airtable Matt worked on the infrastructure team responsible for deploys and thought a lot about how to catch bugs before users did. Deterministic tests are incredibly effective at ensuring pre-defined behavior continues to function, but it's hard to get meaningful coverage & easy to "stub/mock" so much that it's no longer representative of real usage.<p>I like to pitch what we're building now as a set of “users” you can treat like a canary group without worrying about impacting real users.<p>What we do: 
Propolis runs "swarms" of browser agents that collaborate to come up with user journeys, flag points of friction, and propose e2e tests that can then be run more cheaply on any trigger you'd like. We have customers from public companies to startups running "swarms" regularly to massively increase the breadth of their automated testing + running the produced tests as part of their CI pipeline to ensure that more specific flows stay working without needing to worry about updating playwright/selenium tests.<p>One thing that really excites me about this approach is how flexible "checks" can be since they're evaluated partially via LLM, for example we've caught bugs related to the quality of non-deterministic output (think a shopping assistant recommending a product that the user then searches for and can’t find).<p>Pricing and Availability<p>It's production-ready today at $1000/month unlimited-use + active support for early users willing to give feedback and request features. We're also happy to work with you for capped-use / hobby plans at lower prices if you'd like to use it for smaller or personal projects.<p>We'd love to hear from the HN community - especially curious if folks have thoughts on what else autonomous agents could validate beyond bugs and functional correctness. Try it out and let us know what you think!</p>
<hr />
<p>Comments URL: <a href="https://news.ycombinator.com/item?id=45762012">https://news.ycombinator.com/item?id=45762012</a></p>
<p>Points: 93</p>
<p># Comments: 27</p>
    <p><a href="https://app.propolis.tech/#/launch" rel="noopener noreferrer">Source</a></p>
  </main>

  <aside>
    <!-- Paste AdSense snippet here -->

  </aside>

  <script src="/site.js"></script>
</body>
</html>
